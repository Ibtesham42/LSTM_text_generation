{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "120136a1-f8c7-4235-8749-4d98e8b32464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Project\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "865e43a9-8c4e-40a6-9ea0-0d168f8b5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the project gutenberg ebook of the jungle book\\n    \\nthis ebook is for the use of anyone anywhere in the united states and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\nof the project gutenberg license included with this ebook or online\\nat www.gutenberg.org. if you are not located in the united states,\\nyou will have to check the laws of the country where you are located\\nbefore using this ebook.\\n\\ntitle: the jungle book\\n\\nauthor: rudyard kipling\\n\\nrelease date: january 16, 2006 [ebook #236]\\n                most recently updated: may 1, 2023\\n\\nlanguage: english\\n\\n\\n\\n*** start of the project gutenberg ebook the jungle book ***\\n\\n\\n\\n\\nthe jungle book\\n\\nby rudyard kipling\\n\\n\\n\\ncontents\\n\\n     mowgli’s brothers\\n     hunting-song of the seeonee pack\\n     kaa’s hunting\\n     road-song of the bandar-log\\n     “tiger! tiger!”\\n      mowgli’s song\\n     the white seal\\n     lukannon\\n     “rikki-tikki-tavi”\\n      darzee'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'plain.txt'\n",
    "raw_text = open(filename,'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "raw_text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d7e0924-a333-4932-a07e-f0e47588b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Text Cleaning\n",
    "# import re\n",
    "# corpus = []\n",
    "# for i in range(len(raw_text)):\n",
    "#     rp = re.sub('[^a-zA-Z]', \" \",raw_text[i])\n",
    "#     rp = rp.lower()\n",
    "#     rp = rp.split()\n",
    "#     rp = \" \".join(rp)\n",
    "#     corpus.append(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0699d32c-51b1-4ee4-8dcd-d14c925ef934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numbers\n",
    "raw_text = ''.join(i for i in raw_text if not i.isdigit())\n",
    "\n",
    "# Total Character \n",
    "chars = sorted(list(set(raw_text)))\n",
    "\n",
    "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "\n",
    "int_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52edf554-f537-4ed8-b817-7743be59c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Character in Text, Corpus Length 292091\n",
      "Total Vocabulary 54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print('Total Character in Text, Corpus Length',n_chars)\n",
    "print('Total Vocabulary',n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7233f18a-5954-438c-8043-ce104a86365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequence  24335\n"
     ]
    }
   ],
   "source": [
    "seq_length = 80  # length of each i/p sequence\n",
    "step = 12 # instead of moving 1 letter at time try skipping few\n",
    "sentence = [] # Xvalues\n",
    "next_chars =[] # Y_Values\n",
    "\n",
    "for i in range(0,n_chars -seq_length ,step):\n",
    "    sentence.append(raw_text[i:i+seq_length])  # Sentence in\n",
    "    next_chars.append(raw_text[i + seq_length]) # Sentence out\n",
    "n_patterns = len(sentence)\n",
    "print(\"Number of sequence \",n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b67233d-ea65-4e3e-9f17-27df1232a553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24335, 9461)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer()\n",
    "# X = cv.fit_transform(sentence,seq_length).toarray()\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dddfe430-ed71-4dff-917c-c76360146e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24335, 80, 54)\n",
      "(24335, 54)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(sentence), seq_length, n_vocab), dtype=np.bool_)\n",
    "y = np.zeros((len(sentence), n_vocab), dtype=np.bool_)\n",
    "for i, sentences in enumerate(sentence):\n",
    "    for j, char in enumerate(sentences):\n",
    "        X[i,j, char_to_int[char]]=1\n",
    "    y[i,char_to_int[next_chars[i]]] = 1\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cfe9d770-6315-450a-9c77-774cd8ddc880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">94,944</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">7,020</span> │\n",
       "└───────────────────────────────┴───────────────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m)           │       \u001b[38;5;34m94,944\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)            │        \u001b[38;5;34m7,020\u001b[0m │\n",
       "└───────────────────────────────┴───────────────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,964</span> (398.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,964\u001b[0m (398.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,964</span> (398.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,964\u001b[0m (398.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(129, input_shape=(seq_length,n_vocab)))\n",
    "model.add(Dense(n_vocab,activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be603e-d5a1-4b59-997b-70fb600a0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define the checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath,monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "history = model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=100,   \n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "model.save('my_saved_weights_jungle_book_50epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aeb4db-4173-4a75-a434-220fb6c591e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297c0d6-27cf-45bc-944f-12972c56c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcb0f1-6c42-4cc4-aa7c-5ab9d9f2e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "# load the network weights\n",
    "filename = \"my_saved_weights_jungle_book_50epochs.h5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "#Pick a random sentence from the text as seed.\n",
    "start_index = random.randint(0, n_chars - seq_length - 1)\n",
    "\n",
    "#Initiate generated text and keep adding new predictions and print them out\n",
    "generated = ''\n",
    "sentence = raw_text[start_index: start_index + seq_length]\n",
    "generated += sentence\n",
    "\n",
    "print('----- Seed for our text prediction: \"' + sentence + '\"')\n",
    "#sys.stdout.write(generated)\n",
    "\n",
    "\n",
    "for i in range(400):   # Number of characters including spaces\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = int_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275ca1a-6cb4-4a68-ac35-043f4f2b9a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68380a41-b07e-4dc4-9cc5-1a30fe30fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2522caa-14a5-4ebc-a01d-b53fbe00be2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c8c60ae7-8622-4866-996e-9a124f53e2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'my_saved_weights_jungle_book_50epochs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 35\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# --- Ensure your model architecture is defined exactly as during training ---\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# from tensorflow.keras.models import Sequential\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- Load weights (file path must exist) ---\u001b[39;00m\n\u001b[0;32m     34\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_saved_weights_jungle_book_50epochs.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(filename)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# --- Pick random seed sentence from raw_text (make sure raw_text is defined) ---\u001b[39;00m\n\u001b[0;32m     38\u001b[0m start_index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, n_chars \u001b[38;5;241m-\u001b[39m seq_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'my_saved_weights_jungle_book_50epochs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3292c-c8a3-48ea-a694-b402b93de85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc64c0e-97e0-42ea-b6aa-0128611a11b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08cd37-e72a-4a88-8a05-b7551faf0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
